W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
---------------------------------
Run id: 8M72QB
Log directory: /tmp/tflearn_logs/
---------------------------------
Training samples: 22500
Validation samples: 2500
--
E tensorflow/core/util/events_writer.cc:131] Failed to flush 357 events to /tmp/tflearn_logs/8M72QB/events.out.tfevents.1492803940.Michael-Tu392/22500
Training Step: 704  | total loss: 0.41921 | time: 211.193s
| Adam | epoch: 001 | loss: 0.41921 - acc: 0.8353 | val_loss: 0.45697 - val_acc: 0.8068 -- iter: 22500/22500
--
Training Step: 1408  | total loss: 0.29479 | time: 137.310s
| Adam | epoch: 002 | loss: 0.29479 - acc: 0.8834 | val_loss: 0.42652 - val_acc: 0.8160 -- iter: 22500/22500
--
Training Step: 2112  | total loss: 0.24765 | time: 142.337s
| Adam | epoch: 003 | loss: 0.24765 - acc: 0.9109 | val_loss: 0.44830 - val_acc: 0.8304 -- iter: 22500/22500
--
Training Step: 2816  | total loss: 0.16515 | time: 135.738s
| Adam | epoch: 004 | loss: 0.16515 - acc: 0.9411 | val_loss: 0.47949 - val_acc: 0.8144 -- iter: 22500/22500
--
Training Step: 3520  | total loss: 0.13006 | time: 136.116s
| Adam | epoch: 005 | loss: 0.13006 - acc: 0.9599 | val_loss: 0.58520 - val_acc: 0.8152 -- iter: 22500/22500
--
Training Step: 4224  | total loss: 0.12249 | time: 135.537s
| Adam | epoch: 006 | loss: 0.12249 - acc: 0.9684 | val_loss: 0.62204 - val_acc: 0.8120 -- iter: 22500/22500
--
Training Step: 4928  | total loss: 0.09797 | time: 137.129s
| Adam | epoch: 007 | loss: 0.09797 - acc: 0.9737 | val_loss: 0.65720 - val_acc: 0.8116 -- iter: 22500/22500
--
Training Step: 5632  | total loss: 0.06354 | time: 141.099s
| Adam | epoch: 008 | loss: 0.06354 - acc: 0.9780 | val_loss: 0.80513 - val_acc: 0.8204 -- iter: 22500/22500
--
Training Step: 6336  | total loss: 0.02741 | time: 143.562s
| Adam | epoch: 009 | loss: 0.02741 - acc: 0.9956 | val_loss: 0.78169 - val_acc: 0.8148 -- iter: 22500/22500
--
Training Step: 7039  | total loss: 0.01921 | time: 156.540s
| Adam | epoch: 010 | loss: 0.01921 - acc: 0.9949 -- iter: 22496/22500

